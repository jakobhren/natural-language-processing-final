{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Final Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real - Fake News Classification: A Comparison of Natural Language Models for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df_raw = pd.read_csv(\"data/news_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  label  \n",
       "0  December 31, 2017      0  \n",
       "1  December 31, 2017      0  \n",
       "2  December 30, 2017      0  \n",
       "3  December 29, 2017      0  \n",
       "4  December 25, 2017      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw[['title', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House ethics panel investigating Democrat Corr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain sacks Catalan government after independe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California Senate passes gun control package</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EU seeks to end Brexit transition no later tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Another Trump Official Decides It’s A REALLY ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  House ethics panel investigating Democrat Corr...      1\n",
       "1  Spain sacks Catalan government after independe...      1\n",
       "2       California Senate passes gun control package      1\n",
       "3  EU seeks to end Brexit transition no later tha...      1\n",
       "4   Another Trump Official Decides It’s A REALLY ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jakobhren/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jakobhren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jakobhren/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    text = text.str.lower()\n",
    "    \n",
    "    # this remove links and twitter handels, and emails etc\n",
    "    text = text.str.replace(r'http\\S+|www\\S+|https\\S+', '', regex=True)\n",
    "    text = text.str.replace(r'\\S+@\\S+', '', regex=True)\n",
    "    text = text.str.replace(r'@\\w+', '', regex=True)\n",
    "    \n",
    "    text = text.str.replace(f'[{string.punctuation}]', '', regex=True)\n",
    "    \n",
    "    text = text.str.replace(r'\\d+', '', regex=True)\n",
    "    \n",
    "    text = text.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    \n",
    "    text_tokens = text.apply(nltk.word_tokenize)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_tokens = text_tokens.apply(lambda tokens: [w for w in tokens if w not in stop_words])\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_tokens = text_tokens.apply(lambda tokens: [lemmatizer.lemmatize(w) for w in tokens])\n",
    "    \n",
    "    processed_text = text_tokens.apply(lambda tokens: ' '.join(tokens))\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature\"] = preprocess_text(df[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.feature\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=7)\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27110,)\n",
      "(5809,)\n",
      "(5810,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for efficient model evaluation and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(y_true, y_pred_dict, label=None):\n",
    "    \"\"\"\n",
    "    Evaluate and compare multiple models' predictions.\n",
    "    Parameters:\n",
    "    y_true : array-like\n",
    "        True labels.\n",
    "    y_pred_dict : dict\n",
    "        Dictionary where keys are model names and values are predicted labels.\n",
    "    label : str, optional\n",
    "        Description of the evaluation set (e.g., \"Validation Set\").\n",
    "    Returns:\n",
    "    pd.DataFrame containing accuracy, precision, recall, and F1 for each model.\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-score': []\n",
    "    }\n",
    "\n",
    "    for model_name, y_pred in y_pred_dict.items():\n",
    "        print(f\"\\n===== {model_name}: {label if label else ''} =====\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "        metrics['Model'].append(model_name)\n",
    "        metrics['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        unique_labels = np.unique(y_true)\n",
    "        if len(unique_labels) == 2:\n",
    "            metrics['Precision'].append(precision_score(y_true, y_pred, average='binary', pos_label=unique_labels[1]))\n",
    "            metrics['Recall'].append(recall_score(y_true, y_pred, average='binary', pos_label=unique_labels[1]))\n",
    "            metrics['F1-score'].append(f1_score(y_true, y_pred, average='binary', pos_label=unique_labels[1]))\n",
    "        else:\n",
    "            metrics['Precision'].append(precision_score(y_true, y_pred, average='weighted'))\n",
    "            metrics['Recall'].append(recall_score(y_true, y_pred, average='weighted'))\n",
    "            metrics['F1-score'].append(f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "    return pd.DataFrame(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipeline_predict_evaluate(\n",
    "    model_class,\n",
    "    model_name,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    vectorizer_type='tfidf',\n",
    "    ngram_range=(1,1)\n",
    "):\n",
    "    if vectorizer_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "    elif vectorizer_type == 'bow':\n",
    "        vectorizer = CountVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "    elif vectorizer_type is None:\n",
    "        vectorizer = None\n",
    "    else:\n",
    "        raise ValueError(\"vectorizer_type must be either 'tfidf' or 'bow'\")\n",
    "\n",
    "    if vectorizer:\n",
    "        pipeline = make_pipeline(vectorizer, model_class)\n",
    "    else:\n",
    "        pipeline = model_class\n",
    "\n",
    "    print(f\"Fitting {model_name}...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Predicting on training set...\")\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "\n",
    "    print(f\"Predicting on validation set...\")\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "    print(f\"Evaluating {model_name} on training set...\")\n",
    "    train_metrics = evaluate_models(y_train, {model_name: y_pred_train}, label=\"Train Set\")\n",
    "\n",
    "    print(f\"Evaluating {model_name} on validation set...\")\n",
    "    val_metrics = evaluate_models(y_val, {model_name: y_pred_val}, label=\"Validation Set\")\n",
    "\n",
    "    train_metrics[\"Dataset\"] = \"Train\"\n",
    "    val_metrics[\"Dataset\"] = \"Validation\"\n",
    "\n",
    "    return pd.concat([train_metrics, val_metrics], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag Of Words + Unigrams Vecotrizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression (BoW)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Logistic Regression (BoW) on training set...\n",
      "\n",
      "===== Logistic Regression (BoW): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93     12532\n",
      "           1       0.92      0.97      0.95     14578\n",
      "\n",
      "    accuracy                           0.94     27110\n",
      "   macro avg       0.94      0.94      0.94     27110\n",
      "weighted avg       0.94      0.94      0.94     27110\n",
      "\n",
      "Evaluating Logistic Regression (BoW) on validation set...\n",
      "\n",
      "===== Logistic Regression (BoW): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      2685\n",
      "           1       0.90      0.96      0.93      3124\n",
      "\n",
      "    accuracy                           0.92      5809\n",
      "   macro avg       0.93      0.92      0.92      5809\n",
      "weighted avg       0.92      0.92      0.92      5809\n",
      "\n",
      "                       Model  Accuracy  Precision    Recall  F1-score  \\\n",
      "0  Logistic Regression (BoW)  0.939432   0.921149  0.970435  0.945150   \n",
      "1  Logistic Regression (BoW)  0.922018   0.902380  0.958707  0.929691   \n",
      "\n",
      "      Dataset  \n",
      "0       Train  \n",
      "1  Validation  \n"
     ]
    }
   ],
   "source": [
    "logistic_bow_uni_metrics = fit_pipeline_predict_evaluate(\n",
    "    LogisticRegression(penalty='l2', C=0.1,max_iter=1000),\n",
    "    \"Logistic Regression (BoW)\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "print(logistic_bow_uni_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Multinomial Naive Bayes (BoW Unigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Multinomial Naive Bayes (BoW Unigrams) on training set...\n",
      "\n",
      "===== Multinomial Naive Bayes (BoW Unigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     12532\n",
      "           1       0.95      0.94      0.95     14578\n",
      "\n",
      "    accuracy                           0.94     27110\n",
      "   macro avg       0.94      0.94      0.94     27110\n",
      "weighted avg       0.94      0.94      0.94     27110\n",
      "\n",
      "Evaluating Multinomial Naive Bayes (BoW Unigrams) on validation set...\n",
      "\n",
      "===== Multinomial Naive Bayes (BoW Unigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2685\n",
      "           1       0.95      0.93      0.94      3124\n",
      "\n",
      "    accuracy                           0.93      5809\n",
      "   macro avg       0.93      0.93      0.93      5809\n",
      "weighted avg       0.93      0.93      0.93      5809\n",
      "\n",
      "                                    Model  Accuracy  Precision    Recall  \\\n",
      "0  Multinomial Naive Bayes (BoW Unigrams)  0.943268   0.949779  0.944437   \n",
      "1  Multinomial Naive Bayes (BoW Unigrams)  0.932002   0.945478  0.927017   \n",
      "\n",
      "   F1-score     Dataset  \n",
      "0  0.947101       Train  \n",
      "1  0.936156  Validation  \n"
     ]
    }
   ],
   "source": [
    "bow_uni_nb_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=MultinomialNB(alpha=3),\n",
    "    model_name=\"Multinomial Naive Bayes (BoW Unigrams)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "print(bow_uni_nb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest (BoW Unigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Random Forest (BoW Unigrams) on training set...\n",
      "\n",
      "===== Random Forest (BoW Unigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     12532\n",
      "           1       0.88      0.96      0.91     14578\n",
      "\n",
      "    accuracy                           0.90     27110\n",
      "   macro avg       0.91      0.90      0.90     27110\n",
      "weighted avg       0.91      0.90      0.90     27110\n",
      "\n",
      "Evaluating Random Forest (BoW Unigrams) on validation set...\n",
      "\n",
      "===== Random Forest (BoW Unigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      2685\n",
      "           1       0.87      0.94      0.91      3124\n",
      "\n",
      "    accuracy                           0.90      5809\n",
      "   macro avg       0.90      0.89      0.89      5809\n",
      "weighted avg       0.90      0.90      0.89      5809\n",
      "\n",
      "                          Model  Accuracy  Precision    Recall  F1-score  \\\n",
      "0  Random Forest (BoW Unigrams)  0.903467   0.876392  0.955206  0.914104   \n",
      "1  Random Forest (BoW Unigrams)  0.895163   0.871492  0.944302  0.906437   \n",
      "\n",
      "      Dataset  \n",
      "0       Train  \n",
      "1  Validation  \n"
     ]
    }
   ],
   "source": [
    "bow_uni_rf_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class= RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=120,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=7),\n",
    "    model_name=\"Random Forest (BoW Unigrams)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "print(bow_uni_rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MLP...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating MLP on training set...\n",
      "\n",
      "===== MLP: Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95     12532\n",
      "           1       0.95      0.98      0.96     14578\n",
      "\n",
      "    accuracy                           0.96     27110\n",
      "   macro avg       0.96      0.96      0.96     27110\n",
      "weighted avg       0.96      0.96      0.96     27110\n",
      "\n",
      "Evaluating MLP on validation set...\n",
      "\n",
      "===== MLP: Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      2685\n",
      "           1       0.92      0.95      0.94      3124\n",
      "\n",
      "    accuracy                           0.93      5809\n",
      "   macro avg       0.93      0.93      0.93      5809\n",
      "weighted avg       0.93      0.93      0.93      5809\n",
      "\n",
      "  Model  Accuracy  Precision    Recall  F1-score     Dataset\n",
      "0   MLP  0.958871   0.949456  0.975442  0.962274       Train\n",
      "1   MLP  0.931141   0.920111  0.954866  0.937166  Validation\n"
     ]
    }
   ],
   "source": [
    "bow_uni_mlp_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=MLPClassifier(\n",
    "    hidden_layer_sizes=(32,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.5,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    "    random_state=7\n",
    "),\n",
    "    model_name=\"MLP\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "print(bow_uni_mlp_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words + Bigrams Vecotrizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression (BoW + Bigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Logistic Regression (BoW + Bigrams) on training set...\n",
      "\n",
      "===== Logistic Regression (BoW + Bigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94     12532\n",
      "           1       0.92      0.98      0.95     14578\n",
      "\n",
      "    accuracy                           0.94     27110\n",
      "   macro avg       0.95      0.94      0.94     27110\n",
      "weighted avg       0.94      0.94      0.94     27110\n",
      "\n",
      "Evaluating Logistic Regression (BoW + Bigrams) on validation set...\n",
      "\n",
      "===== Logistic Regression (BoW + Bigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      2685\n",
      "           1       0.89      0.97      0.93      3124\n",
      "\n",
      "    accuracy                           0.92      5809\n",
      "   macro avg       0.92      0.91      0.92      5809\n",
      "weighted avg       0.92      0.92      0.92      5809\n",
      "\n",
      "                                 Model  Accuracy  Precision    Recall  \\\n",
      "0  Logistic Regression (BoW + Bigrams)  0.943084   0.921763  0.977089   \n",
      "1  Logistic Regression (BoW + Bigrams)  0.917197   0.888791  0.967029   \n",
      "\n",
      "   F1-score     Dataset  \n",
      "0  0.948620       Train  \n",
      "1  0.926261  Validation  \n"
     ]
    }
   ],
   "source": [
    "logistic_bow_bigrams_metrics = fit_pipeline_predict_evaluate(\n",
    "    LogisticRegression(penalty='l2', C=0.05,max_iter=1000),\n",
    "    \"Logistic Regression (BoW + Bigrams)\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "print(logistic_bow_bigrams_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Multinomial Naive Bayes (BoW Bigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Multinomial Naive Bayes (BoW Bigrams) on training set...\n",
      "\n",
      "===== Multinomial Naive Bayes (BoW Bigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     12532\n",
      "           1       0.96      0.95      0.95     14578\n",
      "\n",
      "    accuracy                           0.95     27110\n",
      "   macro avg       0.95      0.95      0.95     27110\n",
      "weighted avg       0.95      0.95      0.95     27110\n",
      "\n",
      "Evaluating Multinomial Naive Bayes (BoW Bigrams) on validation set...\n",
      "\n",
      "===== Multinomial Naive Bayes (BoW Bigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      2685\n",
      "           1       0.94      0.91      0.93      3124\n",
      "\n",
      "    accuracy                           0.92      5809\n",
      "   macro avg       0.92      0.92      0.92      5809\n",
      "weighted avg       0.92      0.92      0.92      5809\n",
      "\n",
      "                                   Model  Accuracy  Precision    Recall  \\\n",
      "0  Multinomial Naive Bayes (BoW Bigrams)  0.950793   0.958524  0.949582   \n",
      "1  Multinomial Naive Bayes (BoW Bigrams)  0.922534   0.940382  0.913892   \n",
      "\n",
      "   F1-score     Dataset  \n",
      "0  0.954032       Train  \n",
      "1  0.926948  Validation  \n"
     ]
    }
   ],
   "source": [
    "bow_bi_nb_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=MultinomialNB(alpha=10),\n",
    "    model_name=\"Multinomial Naive Bayes (BoW Bigrams)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(bow_bi_nb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest (BoW Bigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Random Forest (BoW Bigrams) on training set...\n",
      "\n",
      "===== Random Forest (BoW Bigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89     12532\n",
      "           1       0.86      0.98      0.92     14578\n",
      "\n",
      "    accuracy                           0.90     27110\n",
      "   macro avg       0.91      0.90      0.90     27110\n",
      "weighted avg       0.91      0.90      0.90     27110\n",
      "\n",
      "Evaluating Random Forest (BoW Bigrams) on validation set...\n",
      "\n",
      "===== Random Forest (BoW Bigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88      2685\n",
      "           1       0.86      0.97      0.91      3124\n",
      "\n",
      "    accuracy                           0.90      5809\n",
      "   macro avg       0.91      0.89      0.90      5809\n",
      "weighted avg       0.91      0.90      0.90      5809\n",
      "\n",
      "                         Model  Accuracy  Precision    Recall  F1-score  \\\n",
      "0  Random Forest (BoW Bigrams)  0.902988   0.862456  0.975099  0.915325   \n",
      "1  Random Forest (BoW Bigrams)  0.898778   0.859003  0.971191  0.911659   \n",
      "\n",
      "      Dataset  \n",
      "0       Train  \n",
      "1  Validation  \n"
     ]
    }
   ],
   "source": [
    "bow_bi_rf_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=120,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=7),\n",
    "    model_name=\"Random Forest (BoW Bigrams)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(bow_bi_rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MLP...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating MLP on training set...\n",
      "\n",
      "===== MLP: Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     12532\n",
      "           1       0.98      0.99      0.99     14578\n",
      "\n",
      "    accuracy                           0.99     27110\n",
      "   macro avg       0.99      0.99      0.99     27110\n",
      "weighted avg       0.99      0.99      0.99     27110\n",
      "\n",
      "Evaluating MLP on validation set...\n",
      "\n",
      "===== MLP: Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2685\n",
      "           1       0.92      0.96      0.94      3124\n",
      "\n",
      "    accuracy                           0.94      5809\n",
      "   macro avg       0.94      0.93      0.94      5809\n",
      "weighted avg       0.94      0.94      0.94      5809\n",
      "\n",
      "  Model  Accuracy  Precision    Recall  F1-score     Dataset\n",
      "0   MLP  0.986094   0.984974  0.989230  0.987097       Train\n",
      "1   MLP  0.935617   0.924383  0.958707  0.941232  Validation\n"
     ]
    }
   ],
   "source": [
    "bow_bi_mlp_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=MLPClassifier(\n",
    "    hidden_layer_sizes=(32,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.5,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    "    random_state=7\n",
    "),\n",
    "    model_name=\"MLP\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "print(bow_bi_mlp_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Logistic Regression on training set...\n",
      "\n",
      "===== Logistic Regression: Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90     12532\n",
      "           1       0.88      0.97      0.92     14578\n",
      "\n",
      "    accuracy                           0.91     27110\n",
      "   macro avg       0.92      0.91      0.91     27110\n",
      "weighted avg       0.92      0.91      0.91     27110\n",
      "\n",
      "Evaluating Logistic Regression on validation set...\n",
      "\n",
      "===== Logistic Regression: Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      2685\n",
      "           1       0.88      0.96      0.92      3124\n",
      "\n",
      "    accuracy                           0.91      5809\n",
      "   macro avg       0.91      0.90      0.91      5809\n",
      "weighted avg       0.91      0.91      0.91      5809\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1-score     Dataset\n",
      "0  Logistic Regression  0.914349   0.884008  0.967691  0.923959       Train\n",
      "1  Logistic Regression  0.908074   0.877992  0.962868  0.918473  Validation\n"
     ]
    }
   ],
   "source": [
    "logistic_tfidf_metrics = fit_pipeline_predict_evaluate(\n",
    "    LogisticRegression(penalty='l2', C=0.1, max_iter=1000),\n",
    "    \"Logistic Regression\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    vectorizer_type='tfidf',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "print(logistic_tfidf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Multinomial Naive Bayes (TF-IDF Unigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Multinomial Naive Bayes (TF-IDF Unigrams) on training set...\n",
      "\n",
      "===== Multinomial Naive Bayes (TF-IDF Unigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93     12532\n",
      "           1       0.92      0.96      0.94     14578\n",
      "\n",
      "    accuracy                           0.93     27110\n",
      "   macro avg       0.94      0.93      0.93     27110\n",
      "weighted avg       0.94      0.93      0.93     27110\n",
      "\n",
      "Evaluating Multinomial Naive Bayes (TF-IDF Unigrams) on validation set...\n",
      "\n",
      "===== Multinomial Naive Bayes (TF-IDF Unigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      2685\n",
      "           1       0.91      0.95      0.93      3124\n",
      "\n",
      "    accuracy                           0.92      5809\n",
      "   macro avg       0.92      0.92      0.92      5809\n",
      "weighted avg       0.92      0.92      0.92      5809\n",
      "\n",
      "                                       Model  Accuracy  Precision    Recall  \\\n",
      "0  Multinomial Naive Bayes (TF-IDF Unigrams)  0.934858   0.918693  0.964193   \n",
      "1  Multinomial Naive Bayes (TF-IDF Unigrams)  0.921157   0.908645  0.948784   \n",
      "\n",
      "   F1-score     Dataset  \n",
      "0  0.940893       Train  \n",
      "1  0.928281  Validation  \n"
     ]
    }
   ],
   "source": [
    "tfidf_uni_nb_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=MultinomialNB(alpha=7),\n",
    "    model_name=\"Multinomial Naive Bayes (TF-IDF Unigrams)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='tfidf',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "print(tfidf_uni_nb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest (TF-IDF Unigrams)...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating Random Forest (TF-IDF Unigrams) on training set...\n",
      "\n",
      "===== Random Forest (TF-IDF Unigrams): Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     12532\n",
      "           1       0.89      0.95      0.92     14578\n",
      "\n",
      "    accuracy                           0.91     27110\n",
      "   macro avg       0.91      0.91      0.91     27110\n",
      "weighted avg       0.91      0.91      0.91     27110\n",
      "\n",
      "Evaluating Random Forest (TF-IDF Unigrams) on validation set...\n",
      "\n",
      "===== Random Forest (TF-IDF Unigrams): Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      2685\n",
      "           1       0.88      0.95      0.91      3124\n",
      "\n",
      "    accuracy                           0.90      5809\n",
      "   macro avg       0.91      0.90      0.90      5809\n",
      "weighted avg       0.90      0.90      0.90      5809\n",
      "\n",
      "                             Model  Accuracy  Precision    Recall  F1-score  \\\n",
      "0  Random Forest (TF-IDF Unigrams)  0.909480   0.887398  0.952531  0.918812   \n",
      "1  Random Forest (TF-IDF Unigrams)  0.901532   0.879310  0.946863  0.911837   \n",
      "\n",
      "      Dataset  \n",
      "0       Train  \n",
      "1  Validation  \n"
     ]
    }
   ],
   "source": [
    "tfidf_uni_rf_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=120,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=7),\n",
    "    model_name=\"Random Forest (TF-IDF Unigrams)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='tfidf',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "print(tfidf_uni_rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MLP...\n",
      "Predicting on training set...\n",
      "Predicting on validation set...\n",
      "Evaluating MLP on training set...\n",
      "\n",
      "===== MLP: Train Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95     12532\n",
      "           1       0.95      0.98      0.96     14578\n",
      "\n",
      "    accuracy                           0.96     27110\n",
      "   macro avg       0.96      0.96      0.96     27110\n",
      "weighted avg       0.96      0.96      0.96     27110\n",
      "\n",
      "Evaluating MLP on validation set...\n",
      "\n",
      "===== MLP: Validation Set =====\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      2685\n",
      "           1       0.92      0.95      0.94      3124\n",
      "\n",
      "    accuracy                           0.93      5809\n",
      "   macro avg       0.93      0.93      0.93      5809\n",
      "weighted avg       0.93      0.93      0.93      5809\n",
      "\n",
      "  Model  Accuracy  Precision    Recall  F1-score     Dataset\n",
      "0   MLP  0.958871   0.949456  0.975442  0.962274       Train\n",
      "1   MLP  0.931141   0.920111  0.954866  0.937166  Validation\n"
     ]
    }
   ],
   "source": [
    "tfidf_uni_mlp_metrics = fit_pipeline_predict_evaluate(\n",
    "    model_class=MLPClassifier(\n",
    "    hidden_layer_sizes=(32,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.5,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    "    random_state=7\n",
    "),\n",
    "    model_name=\"MLP\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    vectorizer_type='bow',\n",
    "    ngram_range=(1,1)\n",
    ")\n",
    "print(tfidf_uni_mlp_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'Trainer'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2073\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2045\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2045\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2046\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2075\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2075\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2073\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/integrations/integration_utils.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel, TrainingArguments\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2048\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2048\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m   2049\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Are this object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms requirements defined correctly?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2050\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'TFPreTrainedModel'. Are this object's requirements defined correctly?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2045\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2045\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2046\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2075\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2075\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nCould not import module 'TFPreTrainedModel'. Are this object's requirements defined correctly?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2073\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2048\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2048\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m   2049\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Are this object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms requirements defined correctly?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2050\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'get_reporting_integration_callbacks'. Are this object's requirements defined correctly?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2045\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2045\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2046\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2075\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2075\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nCould not import module 'get_reporting_integration_callbacks'. Are this object's requirements defined correctly?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py:2048\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2046\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2048\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m   2049\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Are this object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms requirements defined correctly?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2050\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m   2053\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'Trainer'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m DistilBertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m DistilBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m val_encodings \u001b[38;5;241m=\u001b[39m tokenizer(X_val, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTextDataset\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2867\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2865\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2866\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2867\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2869\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2927\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2924\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2929\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2930\u001b[0m     )\n\u001b[1;32m   2932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2936\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, y_train)\n",
    "val_dataset = TextDataset(val_encodings, y_val)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
